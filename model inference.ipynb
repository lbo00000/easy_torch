{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21e9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在CPU上读取.pth文件\n",
    "# 即使模型是在GPU上训练和保存的，您也可以在CPU上加载该模型。加载时需要将模型参数映射到CPU设备。以下是具体步骤：\n",
    "\n",
    "# 加载模型并将其映射到CPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed70b9a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 加载模型权重，并将其映射到CPU\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_your_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 将模型设置为评估模式\u001b[39;00m\n",
      "File \u001b[1;32mD:\\program\\pythonProject\\federated_learning\\venv\\lib\\site-packages\\torch\\serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mD:\\program\\pythonProject\\federated_learning\\venv\\lib\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mD:\\program\\pythonProject\\federated_learning\\venv\\lib\\site-packages\\torch\\serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# 定义模型\n",
    "model = models.resnet18()\n",
    "\n",
    "# 加载模型权重，并将其映射到CPU\n",
    "checkpoint = torch.load('path_to_your_model.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 您现在可以使用model在CPU上进行推理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型转换为ONNX格式并在CPU上使用\n",
    "# 以下是将PyTorch模型转换为ONNX格式的步骤：\n",
    "\n",
    "# 安装必要的库：\n",
    "# 确保您已经安装了PyTorch和ONNX："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a29338",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型并导出为ONNX："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# 定义模型\n",
    "model = models.resnet18()\n",
    "\n",
    "# 加载模型权重，并将其映射到CPU\n",
    "checkpoint = torch.load('path_to_your_model.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 创建一个dummy输入，用于导出模型\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 导出模型为ONNX格式\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\", \n",
    "                  opset_version=11,\n",
    "                  input_names=['input'], \n",
    "                  output_names=['output'])\n",
    "\n",
    "print(\"Model has been converted to ONNX and saved as 'model.onnx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7511d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ONNX模型进行推理：\n",
    "# 您可以使用ONNX Runtime在CPU上加载和运行ONNX模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f37623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加载ONNX模型\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# 创建ONNX Runtime推理会话\n",
    "ort_session = ort.InferenceSession(\"model.onnx\")\n",
    "\n",
    "# 准备输入数据（确保与dummy_input的形状匹配）\n",
    "input_data = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "\n",
    "# 执行推理\n",
    "outputs = ort_session.run(None, {'input': input_data})\n",
    "\n",
    "# 输出结果\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过以上步骤，您可以在CPU上成功读取GPU设备上保存的模型checkpoint，并且可以将其转换为ONNX格式以便在CPU上进行推理。\n",
    "# 这使得模型的使用更加灵活，无论在什么设备上训练，都可以在不同设备上进行推理和部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e9aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72496ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
